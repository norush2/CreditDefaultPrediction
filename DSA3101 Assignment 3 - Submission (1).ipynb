{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36ae997d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, mean_squared_error, auc, roc_curve\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "import math\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import RFECV\n",
    "from scipy.stats import pointbiserialr\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9334f009",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4773bbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15a2897b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                    int64\n",
       "CHK_ACCT              int64\n",
       "DURATION              int64\n",
       "HISTORY               int64\n",
       "NEW_CAR               int64\n",
       "USED_CAR              int64\n",
       "FURNITURE             int64\n",
       "RADIO_TV              int64\n",
       "EDUCATION           float64\n",
       "RETRAINING            int64\n",
       "AMOUNT              float64\n",
       "SAV_ACCT              int64\n",
       "EMPLOYMENT            int64\n",
       "INSTALL_RATE          int64\n",
       "MALE_DIV              int64\n",
       "MALE_SINGLE           int64\n",
       "MALE_MAR_or_WID       int64\n",
       "CO_APPLICANT          int64\n",
       "GUARANTOR             int64\n",
       "PRESENT_RESIDENT      int64\n",
       "REAL_ESTATE           int64\n",
       "PROP_UNKN_NONE        int64\n",
       "AGE                   int64\n",
       "OTHER_INSTALL         int64\n",
       "RENT                float64\n",
       "OWN_RES               int64\n",
       "NUM_CREDITS           int64\n",
       "JOB                 float64\n",
       "NUM_DEPENDENTS        int64\n",
       "TELEPHONE             int64\n",
       "FOREIGN               int64\n",
       "RESPONSE              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a500ed6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#examine missing values\n",
    "data.isnull().sum()\n",
    "#since there are not too many missing values, we can remove rows(observations) with the missing values\n",
    "data=data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "407347e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop('ID',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c81d9a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.astype({\"JOB\": int, \"EDUCATION\": int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df94e712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#IS OUR DATA BALANCED? (APPLYING REBALANCING LATER ON)\n",
    "data[\"RESPONSE\"].value_counts()\n",
    "data['RESPONSE'].value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "109e085b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  61.,    0.,    0.,  579.,    0.,    0., 1838.,    0.,    0.,\n",
       "         453.]),\n",
       " array([0. , 0.3, 0.6, 0.9, 1.2, 1.5, 1.8, 2.1, 2.4, 2.7, 3. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data.JOB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50dcae54",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_variables = ['DURATION', 'AMOUNT', 'AGE','NUM_CREDITS','NUM_DEPENDENTS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2fffa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals= \",\".join(data.drop(['RESPONSE','DURATION', 'AMOUNT', 'AGE','NUM_CREDITS','NUM_DEPENDENTS'],axis=1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83bc0185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CHK_ACCT,HISTORY,NEW_CAR,USED_CAR,FURNITURE,RADIO_TV,EDUCATION,RETRAINING,SAV_ACCT,EMPLOYMENT,INSTALL_RATE,MALE_DIV,MALE_SINGLE,MALE_MAR_or_WID,CO_APPLICANT,GUARANTOR,PRESENT_RESIDENT,REAL_ESTATE,PROP_UNKN_NONE,OTHER_INSTALL,RENT,OWN_RES,JOB,TELEPHONE,FOREIGN'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d93cf054",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_variables=['CHK_ACCT','HISTORY','NEW_CAR','USED_CAR','FURNITURE','RADIO_TV','EDUCATION','RETRAINING','SAV_ACCT','EMPLOYMENT','INSTALL_RATE','MALE_DIV','MALE_SINGLE','MALE_MAR_or_WID','CO_APPLICANT','GUARANTOR','PRESENT_RESIDENT','REAL_ESTATE','PROP_UNKN_NONE','OTHER_INSTALL','RENT','OWN_RES','JOB','TELEPHONE','FOREIGN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4d39be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following function generates the formula to input into the statsmodel function, \n",
    "# with specified predictors(columns) removed.\n",
    "droplist = ['RESPONSE']\n",
    "\n",
    "def remove_name_formula(toremove):\n",
    "    print(type(toremove))\n",
    "    global droplist\n",
    "    droplist = droplist+toremove\n",
    "    newdf = data.drop(droplist,axis=1)\n",
    "    predictors = \"+\".join(newdf.columns)\n",
    "    f = 'RESPONSE ~ '+predictors\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28f0b124",
   "metadata": {},
   "outputs": [],
   "source": [
    "#relation between categorical and continuous\n",
    "\n",
    "# Find Point biserial correlation\n",
    "for cat_var in categorical_variables:\n",
    "  for cont_var in continuous_variables:\n",
    "    data_cat = data[cat_var].to_numpy()\n",
    "    data_cont = data[cont_var].to_numpy()\n",
    "    \n",
    "    corr, p_val = pointbiserialr(x=data_cat,y=data_cont)\n",
    "    if np.abs(corr) >= 0.7:\n",
    "      print(f'Categorical variable: {cat_var}, Continuous variable: {cont_var}, correlation: {corr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb079c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Pearson correlation(for continuous variables)\n",
    "total_len = len(continuous_variables)\n",
    "for idx1 in range(total_len-1):\n",
    "  for idx2 in range(idx1+1, total_len):\n",
    "    cont_var1 = continuous_variables[idx1]\n",
    "    cont_var2 = continuous_variables[idx2]\n",
    "    data_cont1 = data[cont_var1].to_numpy()\n",
    "    data_cont2 = data[cont_var2].to_numpy()\n",
    "    corr, p_val = pearsonr(x=data_cont1, y=data_cont2)\n",
    "    if np.abs(corr) >= 0.7:\n",
    "      print(f'Variable 1: {cont_var1}, Variable 2: {cont_var2}, correlation: {corr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7203c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Cramer's V correlation\n",
    "total_len = len(categorical_variables)\n",
    "for idx1 in range(total_len-1):\n",
    "  for idx2 in range(idx1+1, total_len):\n",
    "    cat_var1 = categorical_variables[idx1]\n",
    "    cat_var2 = categorical_variables[idx2]    \n",
    "    c_matrix = pd.crosstab(data[cat_var1], data[cat_var2])\n",
    "    chi2 = chi2_contingency(c_matrix)[0]\n",
    "    n = c_matrix.sum().sum()\n",
    "    phi2 = chi2/n\n",
    "    r,k = c_matrix.shape\n",
    "    phi2corr = max(0, phi2-((k-1)*(r-1))/(n-1))\n",
    "    rcorr = r-((r-1)**2)/(n-1)\n",
    "    kcorr = k-((k-1)**2)/(n-1)\n",
    "    corr = np.sqrt(phi2corr/min((kcorr-1),(rcorr-1)))\n",
    "    if corr >= 0.7:\n",
    "      print(f'categorical variable 1 {cat_var1}, categorical variable 2: {cat_var2}, correlation: {corr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c84642",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fccf018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHK_ACCT+DURATION+HISTORY+NEW_CAR+USED_CAR+FURNITURE+RADIO_TV+EDUCATION+RETRAINING+AMOUNT+SAV_ACCT+EMPLOYMENT+INSTALL_RATE+MALE_DIV+MALE_SINGLE+MALE_MAR_or_WID+CO_APPLICANT+GUARANTOR+PRESENT_RESIDENT+REAL_ESTATE+PROP_UNKN_NONE+AGE+OTHER_INSTALL+RENT+OWN_RES+NUM_CREDITS+JOB+NUM_DEPENDENTS+TELEPHONE+FOREIGN\n"
     ]
    }
   ],
   "source": [
    "#all predictors\n",
    "all_predictors='+'.join(data.drop(['RESPONSE'],axis=1).columns)\n",
    "print(all_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfeb0c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RESPONSE~CHK_ACCT+DURATION+HISTORY+NEW_CAR+USED_CAR+FURNITURE+RADIO_TV+EDUCATION+RETRAINING+AMOUNT+SAV_ACCT+EMPLOYMENT+INSTALL_RATE+MALE_DIV+MALE_SINGLE+MALE_MAR_or_WID+CO_APPLICANT+GUARANTOR+PRESENT_RESIDENT+REAL_ESTATE+PROP_UNKN_NONE+AGE+OTHER_INSTALL+RENT+OWN_RES+NUM_CREDITS+JOB+NUM_DEPENDENTS+TELEPHONE+FOREIGN'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = 'RESPONSE~'+ all_predictors\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a967414",
   "metadata": {},
   "source": [
    "## First method of doing feature selection using logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03671860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.555637\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               RESPONSE   No. Observations:                 2931\n",
      "Model:                          Logit   Df Residuals:                     2900\n",
      "Method:                           MLE   Df Model:                           30\n",
      "Date:                Wed, 10 Nov 2021   Pseudo R-squ.:                  0.1073\n",
      "Time:                        17:06:09   Log-Likelihood:                -1628.6\n",
      "converged:                       True   LL-Null:                       -1824.4\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.383e-64\n",
      "====================================================================================\n",
      "                       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "Intercept           -0.3229      0.317     -1.018      0.309      -0.945       0.299\n",
      "CHK_ACCT             0.2946      0.035      8.350      0.000       0.225       0.364\n",
      "DURATION            -0.0155      0.004     -4.202      0.000      -0.023      -0.008\n",
      "HISTORY              0.2278      0.042      5.422      0.000       0.145       0.310\n",
      "NEW_CAR              0.0232      0.103      0.226      0.821      -0.178       0.225\n",
      "USED_CAR             0.4491      0.152      2.948      0.003       0.151       0.748\n",
      "FURNITURE           -0.0146      0.111     -0.131      0.895      -0.233       0.203\n",
      "RADIO_TV             0.3127      0.108      2.894      0.004       0.101       0.524\n",
      "EDUCATION            0.1501      0.203      0.740      0.459      -0.248       0.548\n",
      "RETRAINING           0.1246      0.147      0.846      0.398      -0.164       0.413\n",
      "AMOUNT            3.332e-08   3.14e-08      1.060      0.289   -2.83e-08    9.49e-08\n",
      "SAV_ACCT             0.0938      0.029      3.255      0.001       0.037       0.150\n",
      "EMPLOYMENT           0.1650      0.036      4.550      0.000       0.094       0.236\n",
      "INSTALL_RATE        -0.1070      0.043     -2.488      0.013      -0.191      -0.023\n",
      "MALE_DIV            -0.1120      0.203     -0.552      0.581      -0.510       0.286\n",
      "MALE_SINGLE          0.2901      0.095      3.060      0.002       0.104       0.476\n",
      "MALE_MAR_or_WID     -0.0254      0.142     -0.179      0.858      -0.303       0.253\n",
      "CO_APPLICANT        -0.1557      0.205     -0.758      0.448      -0.558       0.247\n",
      "GUARANTOR            0.4890      0.206      2.370      0.018       0.085       0.893\n",
      "PRESENT_RESIDENT    -0.0218      0.041     -0.533      0.594      -0.102       0.058\n",
      "REAL_ESTATE          0.3206      0.107      2.994      0.003       0.111       0.530\n",
      "PROP_UNKN_NONE      -0.2802      0.127     -2.210      0.027      -0.529      -0.032\n",
      "AGE                  0.0004      0.000      0.850      0.395      -0.001       0.001\n",
      "OTHER_INSTALL       -0.2646      0.110     -2.411      0.016      -0.480      -0.049\n",
      "RENT                -0.2886      0.126     -2.287      0.022      -0.536      -0.041\n",
      "OWN_RES              0.3199      0.117      2.745      0.006       0.091       0.548\n",
      "NUM_CREDITS          0.1431      0.099      1.450      0.147      -0.050       0.336\n",
      "JOB                 -0.1603      0.070     -2.296      0.022      -0.297      -0.023\n",
      "NUM_DEPENDENTS      -0.1044      0.123     -0.851      0.395      -0.345       0.136\n",
      "TELEPHONE            0.1695      0.094      1.812      0.070      -0.014       0.353\n",
      "FOREIGN              0.5219      0.269      1.938      0.053      -0.006       1.050\n",
      "====================================================================================\n"
     ]
    }
   ],
   "source": [
    "#fit logistic regression model\n",
    "logitfit = smf.logit(formula = f, data = data).fit()\n",
    "print(logitfit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36d8cdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.555640\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               RESPONSE   No. Observations:                 2931\n",
      "Model:                          Logit   Df Residuals:                     2901\n",
      "Method:                           MLE   Df Model:                           29\n",
      "Date:                Wed, 10 Nov 2021   Pseudo R-squ.:                  0.1073\n",
      "Time:                        17:06:09   Log-Likelihood:                -1628.6\n",
      "converged:                       True   LL-Null:                       -1824.4\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.750e-65\n",
      "====================================================================================\n",
      "                       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "Intercept           -0.3294      0.313     -1.051      0.293      -0.944       0.285\n",
      "CHK_ACCT             0.2947      0.035      8.356      0.000       0.226       0.364\n",
      "DURATION            -0.0155      0.004     -4.200      0.000      -0.023      -0.008\n",
      "HISTORY              0.2278      0.042      5.424      0.000       0.145       0.310\n",
      "NEW_CAR              0.0249      0.102      0.244      0.807      -0.175       0.225\n",
      "USED_CAR             0.4505      0.152      2.965      0.003       0.153       0.748\n",
      "RADIO_TV             0.3144      0.107      2.931      0.003       0.104       0.525\n",
      "EDUCATION            0.1514      0.203      0.747      0.455      -0.246       0.549\n",
      "RETRAINING           0.1256      0.147      0.854      0.393      -0.163       0.414\n",
      "AMOUNT            3.342e-08   3.14e-08      1.064      0.288   -2.82e-08     9.5e-08\n",
      "SAV_ACCT             0.0939      0.029      3.259      0.001       0.037       0.150\n",
      "EMPLOYMENT           0.1653      0.036      4.565      0.000       0.094       0.236\n",
      "INSTALL_RATE        -0.1068      0.043     -2.486      0.013      -0.191      -0.023\n",
      "MALE_DIV            -0.1120      0.203     -0.552      0.581      -0.510       0.286\n",
      "MALE_SINGLE          0.2909      0.095      3.076      0.002       0.106       0.476\n",
      "MALE_MAR_or_WID     -0.0251      0.142     -0.177      0.860      -0.303       0.253\n",
      "CO_APPLICANT        -0.1554      0.205     -0.757      0.449      -0.558       0.247\n",
      "GUARANTOR            0.4899      0.206      2.376      0.018       0.086       0.894\n",
      "PRESENT_RESIDENT    -0.0218      0.041     -0.533      0.594      -0.102       0.058\n",
      "REAL_ESTATE          0.3210      0.107      3.000      0.003       0.111       0.531\n",
      "PROP_UNKN_NONE      -0.2795      0.127     -2.206      0.027      -0.528      -0.031\n",
      "AGE                  0.0004      0.000      0.846      0.397      -0.001       0.001\n",
      "OTHER_INSTALL       -0.2648      0.110     -2.413      0.016      -0.480      -0.050\n",
      "RENT                -0.2894      0.126     -2.296      0.022      -0.536      -0.042\n",
      "OWN_RES              0.3202      0.117      2.747      0.006       0.092       0.549\n",
      "NUM_CREDITS          0.1434      0.099      1.454      0.146      -0.050       0.337\n",
      "JOB                 -0.1606      0.070     -2.302      0.021      -0.297      -0.024\n",
      "NUM_DEPENDENTS      -0.1040      0.123     -0.848      0.396      -0.344       0.136\n",
      "TELEPHONE            0.1697      0.094      1.813      0.070      -0.014       0.353\n",
      "FOREIGN              0.5219      0.269      1.938      0.053      -0.006       1.050\n",
      "====================================================================================\n"
     ]
    }
   ],
   "source": [
    "#looking at the p-values we see that not all variables may be significant\n",
    "#Highest p-value comes from furniture so we can try removing that\n",
    "\n",
    "f = remove_name_formula(['FURNITURE'])\n",
    "logitfit = smf.logit(formula = f, data = data).fit()\n",
    "print(logitfit.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "950c3db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.555645\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               RESPONSE   No. Observations:                 2931\n",
      "Model:                          Logit   Df Residuals:                     2902\n",
      "Method:                           MLE   Df Model:                           28\n",
      "Date:                Wed, 10 Nov 2021   Pseudo R-squ.:                  0.1073\n",
      "Time:                        17:06:10   Log-Likelihood:                -1628.6\n",
      "converged:                       True   LL-Null:                       -1824.4\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.006e-65\n",
      "====================================================================================\n",
      "                       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "Intercept           -0.3382      0.310     -1.093      0.275      -0.945       0.268\n",
      "CHK_ACCT             0.2948      0.035      8.357      0.000       0.226       0.364\n",
      "DURATION            -0.0155      0.004     -4.197      0.000      -0.023      -0.008\n",
      "HISTORY              0.2277      0.042      5.422      0.000       0.145       0.310\n",
      "NEW_CAR              0.0249      0.102      0.245      0.807      -0.175       0.225\n",
      "USED_CAR             0.4503      0.152      2.964      0.003       0.152       0.748\n",
      "RADIO_TV             0.3130      0.107      2.926      0.003       0.103       0.523\n",
      "EDUCATION            0.1513      0.203      0.746      0.455      -0.246       0.549\n",
      "RETRAINING           0.1259      0.147      0.855      0.392      -0.163       0.414\n",
      "AMOUNT            3.331e-08   3.14e-08      1.060      0.289   -2.83e-08    9.49e-08\n",
      "SAV_ACCT             0.0940      0.029      3.263      0.001       0.038       0.150\n",
      "EMPLOYMENT           0.1653      0.036      4.567      0.000       0.094       0.236\n",
      "INSTALL_RATE        -0.1069      0.043     -2.487      0.013      -0.191      -0.023\n",
      "MALE_DIV            -0.1106      0.203     -0.546      0.585      -0.508       0.287\n",
      "MALE_SINGLE          0.2933      0.094      3.133      0.002       0.110       0.477\n",
      "CO_APPLICANT        -0.1548      0.205     -0.754      0.451      -0.557       0.248\n",
      "GUARANTOR            0.4899      0.206      2.375      0.018       0.086       0.894\n",
      "PRESENT_RESIDENT    -0.0213      0.041     -0.524      0.600      -0.101       0.059\n",
      "REAL_ESTATE          0.3207      0.107      2.997      0.003       0.111       0.530\n",
      "PROP_UNKN_NONE      -0.2785      0.127     -2.201      0.028      -0.527      -0.030\n",
      "AGE                  0.0004      0.000      0.850      0.395      -0.001       0.001\n",
      "OTHER_INSTALL       -0.2641      0.110     -2.409      0.016      -0.479      -0.049\n",
      "RENT                -0.2891      0.126     -2.293      0.022      -0.536      -0.042\n",
      "OWN_RES              0.3200      0.117      2.746      0.006       0.092       0.548\n",
      "NUM_CREDITS          0.1437      0.099      1.457      0.145      -0.050       0.337\n",
      "JOB                 -0.1601      0.070     -2.297      0.022      -0.297      -0.023\n",
      "NUM_DEPENDENTS      -0.1027      0.122     -0.839      0.402      -0.343       0.137\n",
      "TELEPHONE            0.1706      0.093      1.826      0.068      -0.013       0.354\n",
      "FOREIGN              0.5215      0.269      1.937      0.053      -0.006       1.049\n",
      "====================================================================================\n"
     ]
    }
   ],
   "source": [
    "f = remove_name_formula(['MALE_MAR_or_WID'])\n",
    "logitfit = smf.logit(formula = f, data = data).fit()\n",
    "print(logitfit.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "529bf9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.555655\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               RESPONSE   No. Observations:                 2931\n",
      "Model:                          Logit   Df Residuals:                     2903\n",
      "Method:                           MLE   Df Model:                           27\n",
      "Date:                Wed, 10 Nov 2021   Pseudo R-squ.:                  0.1073\n",
      "Time:                        17:06:10   Log-Likelihood:                -1628.6\n",
      "converged:                       True   LL-Null:                       -1824.4\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.684e-66\n",
      "====================================================================================\n",
      "                       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "Intercept           -0.3293      0.307     -1.071      0.284      -0.932       0.273\n",
      "CHK_ACCT             0.2942      0.035      8.361      0.000       0.225       0.363\n",
      "DURATION            -0.0155      0.004     -4.224      0.000      -0.023      -0.008\n",
      "HISTORY              0.2274      0.042      5.418      0.000       0.145       0.310\n",
      "USED_CAR             0.4477      0.152      2.954      0.003       0.151       0.745\n",
      "RADIO_TV             0.3088      0.106      2.924      0.003       0.102       0.516\n",
      "EDUCATION            0.1476      0.202      0.730      0.465      -0.249       0.544\n",
      "RETRAINING           0.1223      0.146      0.835      0.404      -0.165       0.409\n",
      "AMOUNT            3.336e-08   3.14e-08      1.062      0.288   -2.82e-08    9.49e-08\n",
      "SAV_ACCT             0.0942      0.029      3.270      0.001       0.038       0.151\n",
      "EMPLOYMENT           0.1652      0.036      4.563      0.000       0.094       0.236\n",
      "INSTALL_RATE        -0.1066      0.043     -2.481      0.013      -0.191      -0.022\n",
      "MALE_DIV            -0.1116      0.203     -0.551      0.582      -0.509       0.286\n",
      "MALE_SINGLE          0.2933      0.094      3.133      0.002       0.110       0.477\n",
      "CO_APPLICANT        -0.1555      0.205     -0.757      0.449      -0.558       0.247\n",
      "GUARANTOR            0.4909      0.206      2.380      0.017       0.087       0.895\n",
      "PRESENT_RESIDENT    -0.0211      0.041     -0.519      0.604      -0.101       0.059\n",
      "REAL_ESTATE          0.3213      0.107      3.004      0.003       0.112       0.531\n",
      "PROP_UNKN_NONE      -0.2774      0.126     -2.193      0.028      -0.525      -0.030\n",
      "AGE                  0.0004      0.000      0.852      0.394      -0.001       0.001\n",
      "OTHER_INSTALL       -0.2647      0.110     -2.414      0.016      -0.480      -0.050\n",
      "RENT                -0.2898      0.126     -2.299      0.021      -0.537      -0.043\n",
      "OWN_RES              0.3197      0.117      2.743      0.006       0.091       0.548\n",
      "NUM_CREDITS          0.1437      0.099      1.457      0.145      -0.050       0.337\n",
      "JOB                 -0.1605      0.070     -2.304      0.021      -0.297      -0.024\n",
      "NUM_DEPENDENTS      -0.1009      0.122     -0.825      0.409      -0.340       0.139\n",
      "TELEPHONE            0.1700      0.093      1.820      0.069      -0.013       0.353\n",
      "FOREIGN              0.5252      0.269      1.954      0.051      -0.002       1.052\n",
      "====================================================================================\n"
     ]
    }
   ],
   "source": [
    "f = remove_name_formula(['NEW_CAR'])\n",
    "logitfit = smf.logit(formula = f, data = data).fit()\n",
    "print(logitfit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "747be5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.555701\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               RESPONSE   No. Observations:                 2931\n",
      "Model:                          Logit   Df Residuals:                     2904\n",
      "Method:                           MLE   Df Model:                           26\n",
      "Date:                Wed, 10 Nov 2021   Pseudo R-squ.:                  0.1072\n",
      "Time:                        17:06:10   Log-Likelihood:                -1628.8\n",
      "converged:                       True   LL-Null:                       -1824.4\n",
      "Covariance Type:            nonrobust   LLR p-value:                 7.752e-67\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept         -0.3814      0.291     -1.313      0.189      -0.951       0.188\n",
      "CHK_ACCT           0.2942      0.035      8.363      0.000       0.225       0.363\n",
      "DURATION          -0.0155      0.004     -4.225      0.000      -0.023      -0.008\n",
      "HISTORY            0.2262      0.042      5.397      0.000       0.144       0.308\n",
      "USED_CAR           0.4451      0.151      2.939      0.003       0.148       0.742\n",
      "RADIO_TV           0.3098      0.106      2.934      0.003       0.103       0.517\n",
      "EDUCATION          0.1432      0.202      0.709      0.478      -0.253       0.539\n",
      "RETRAINING         0.1239      0.146      0.847      0.397      -0.163       0.411\n",
      "AMOUNT          3.334e-08   3.14e-08      1.062      0.288   -2.82e-08    9.49e-08\n",
      "SAV_ACCT           0.0934      0.029      3.246      0.001       0.037       0.150\n",
      "EMPLOYMENT         0.1638      0.036      4.536      0.000       0.093       0.235\n",
      "INSTALL_RATE      -0.1061      0.043     -2.470      0.014      -0.190      -0.022\n",
      "MALE_DIV          -0.1106      0.203     -0.546      0.585      -0.508       0.286\n",
      "MALE_SINGLE        0.2894      0.093      3.102      0.002       0.107       0.472\n",
      "CO_APPLICANT      -0.1548      0.205     -0.755      0.451      -0.557       0.247\n",
      "GUARANTOR          0.4929      0.206      2.391      0.017       0.089       0.897\n",
      "REAL_ESTATE        0.3224      0.107      3.015      0.003       0.113       0.532\n",
      "PROP_UNKN_NONE    -0.2833      0.126     -2.249      0.025      -0.530      -0.036\n",
      "AGE                0.0004      0.000      0.851      0.395      -0.001       0.001\n",
      "OTHER_INSTALL     -0.2646      0.110     -2.413      0.016      -0.479      -0.050\n",
      "RENT              -0.2940      0.126     -2.338      0.019      -0.540      -0.047\n",
      "OWN_RES            0.3294      0.115      2.864      0.004       0.104       0.555\n",
      "NUM_CREDITS        0.1420      0.099      1.441      0.150      -0.051       0.335\n",
      "JOB               -0.1604      0.070     -2.303      0.021      -0.297      -0.024\n",
      "NUM_DEPENDENTS    -0.1031      0.122     -0.844      0.399      -0.342       0.136\n",
      "TELEPHONE          0.1674      0.093      1.794      0.073      -0.015       0.350\n",
      "FOREIGN            0.5268      0.269      1.960      0.050    6.78e-05       1.054\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "f = remove_name_formula(['PRESENT_RESIDENT'])\n",
    "logitfit = smf.logit(formula = f, data = data).fit()\n",
    "print(logitfit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34717649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.555752\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               RESPONSE   No. Observations:                 2931\n",
      "Model:                          Logit   Df Residuals:                     2905\n",
      "Method:                           MLE   Df Model:                           25\n",
      "Date:                Wed, 10 Nov 2021   Pseudo R-squ.:                  0.1071\n",
      "Time:                        17:06:10   Log-Likelihood:                -1628.9\n",
      "converged:                       True   LL-Null:                       -1824.4\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.224e-67\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept         -0.3956      0.289     -1.367      0.172      -0.963       0.171\n",
      "CHK_ACCT           0.2941      0.035      8.360      0.000       0.225       0.363\n",
      "DURATION          -0.0155      0.004     -4.213      0.000      -0.023      -0.008\n",
      "HISTORY            0.2264      0.042      5.403      0.000       0.144       0.309\n",
      "USED_CAR           0.4455      0.151      2.941      0.003       0.149       0.742\n",
      "RADIO_TV           0.3122      0.105      2.959      0.003       0.105       0.519\n",
      "EDUCATION          0.1430      0.202      0.709      0.479      -0.253       0.539\n",
      "RETRAINING         0.1214      0.146      0.830      0.406      -0.165       0.408\n",
      "AMOUNT          3.355e-08   3.14e-08      1.069      0.285    -2.8e-08     9.5e-08\n",
      "SAV_ACCT           0.0935      0.029      3.251      0.001       0.037       0.150\n",
      "EMPLOYMENT         0.1633      0.036      4.525      0.000       0.093       0.234\n",
      "INSTALL_RATE      -0.1046      0.043     -2.441      0.015      -0.189      -0.021\n",
      "MALE_SINGLE        0.2946      0.093      3.174      0.002       0.113       0.476\n",
      "CO_APPLICANT      -0.1528      0.205     -0.745      0.456      -0.555       0.249\n",
      "GUARANTOR          0.4924      0.206      2.388      0.017       0.088       0.896\n",
      "REAL_ESTATE        0.3226      0.107      3.017      0.003       0.113       0.532\n",
      "PROP_UNKN_NONE    -0.2817      0.126     -2.238      0.025      -0.528      -0.035\n",
      "AGE                0.0004      0.000      0.854      0.393      -0.001       0.001\n",
      "OTHER_INSTALL     -0.2636      0.110     -2.405      0.016      -0.478      -0.049\n",
      "RENT              -0.2914      0.126     -2.319      0.020      -0.538      -0.045\n",
      "OWN_RES            0.3286      0.115      2.857      0.004       0.103       0.554\n",
      "NUM_CREDITS        0.1422      0.099      1.443      0.149      -0.051       0.335\n",
      "JOB               -0.1611      0.070     -2.313      0.021      -0.298      -0.025\n",
      "NUM_DEPENDENTS    -0.1007      0.122     -0.825      0.409      -0.340       0.138\n",
      "TELEPHONE          0.1661      0.093      1.781      0.075      -0.017       0.349\n",
      "FOREIGN            0.5264      0.269      1.959      0.050      -0.000       1.053\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "f = remove_name_formula(['MALE_DIV'])\n",
    "logitfit = smf.logit(formula = f, data = data).fit()\n",
    "print(logitfit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "449e8440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.555838\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               RESPONSE   No. Observations:                 2931\n",
      "Model:                          Logit   Df Residuals:                     2906\n",
      "Method:                           MLE   Df Model:                           24\n",
      "Date:                Wed, 10 Nov 2021   Pseudo R-squ.:                  0.1070\n",
      "Time:                        17:06:10   Log-Likelihood:                -1629.2\n",
      "converged:                       True   LL-Null:                       -1824.4\n",
      "Covariance Type:            nonrobust   LLR p-value:                 6.908e-68\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept         -0.3898      0.289     -1.347      0.178      -0.957       0.177\n",
      "CHK_ACCT           0.2941      0.035      8.361      0.000       0.225       0.363\n",
      "DURATION          -0.0155      0.004     -4.216      0.000      -0.023      -0.008\n",
      "HISTORY            0.2273      0.042      5.430      0.000       0.145       0.309\n",
      "USED_CAR           0.4437      0.151      2.932      0.003       0.147       0.740\n",
      "RADIO_TV           0.3072      0.105      2.918      0.004       0.101       0.513\n",
      "RETRAINING         0.1182      0.146      0.809      0.419      -0.168       0.405\n",
      "AMOUNT          3.325e-08   3.14e-08      1.060      0.289   -2.83e-08    9.48e-08\n",
      "SAV_ACCT           0.0933      0.029      3.244      0.001       0.037       0.150\n",
      "EMPLOYMENT         0.1636      0.036      4.534      0.000       0.093       0.234\n",
      "INSTALL_RATE      -0.1029      0.043     -2.405      0.016      -0.187      -0.019\n",
      "MALE_SINGLE        0.2934      0.093      3.162      0.002       0.112       0.475\n",
      "CO_APPLICANT      -0.1526      0.205     -0.744      0.457      -0.555       0.250\n",
      "GUARANTOR          0.4872      0.206      2.365      0.018       0.084       0.891\n",
      "REAL_ESTATE        0.3205      0.107      2.999      0.003       0.111       0.530\n",
      "PROP_UNKN_NONE    -0.2749      0.126     -2.190      0.029      -0.521      -0.029\n",
      "AGE                0.0004      0.000      0.854      0.393      -0.001       0.001\n",
      "OTHER_INSTALL     -0.2597      0.109     -2.372      0.018      -0.474      -0.045\n",
      "RENT              -0.2943      0.126     -2.343      0.019      -0.540      -0.048\n",
      "OWN_RES            0.3245      0.115      2.825      0.005       0.099       0.550\n",
      "NUM_CREDITS        0.1414      0.099      1.436      0.151      -0.052       0.335\n",
      "JOB               -0.1617      0.070     -2.323      0.020      -0.298      -0.025\n",
      "NUM_DEPENDENTS    -0.0994      0.122     -0.815      0.415      -0.338       0.140\n",
      "TELEPHONE          0.1645      0.093      1.765      0.078      -0.018       0.347\n",
      "FOREIGN            0.5241      0.269      1.952      0.051      -0.002       1.050\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "f = remove_name_formula(['EDUCATION'])\n",
    "logitfit = smf.logit(formula = f, data = data).fit()\n",
    "print(logitfit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b976a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.555932\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               RESPONSE   No. Observations:                 2931\n",
      "Model:                          Logit   Df Residuals:                     2907\n",
      "Method:                           MLE   Df Model:                           23\n",
      "Date:                Wed, 10 Nov 2021   Pseudo R-squ.:                  0.1069\n",
      "Time:                        17:06:10   Log-Likelihood:                -1629.4\n",
      "converged:                       True   LL-Null:                       -1824.4\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.144e-68\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept         -0.4052      0.289     -1.404      0.160      -0.971       0.160\n",
      "CHK_ACCT           0.2944      0.035      8.372      0.000       0.225       0.363\n",
      "DURATION          -0.0155      0.004     -4.238      0.000      -0.023      -0.008\n",
      "HISTORY            0.2276      0.042      5.436      0.000       0.146       0.310\n",
      "USED_CAR           0.4480      0.151      2.962      0.003       0.152       0.744\n",
      "RADIO_TV           0.3067      0.105      2.914      0.004       0.100       0.513\n",
      "RETRAINING         0.1187      0.146      0.812      0.417      -0.168       0.405\n",
      "AMOUNT          3.266e-08   3.14e-08      1.041      0.298   -2.88e-08    9.41e-08\n",
      "SAV_ACCT           0.0938      0.029      3.263      0.001       0.037       0.150\n",
      "EMPLOYMENT         0.1649      0.036      4.575      0.000       0.094       0.236\n",
      "INSTALL_RATE      -0.1021      0.043     -2.389      0.017      -0.186      -0.018\n",
      "MALE_SINGLE        0.2939      0.093      3.168      0.002       0.112       0.476\n",
      "GUARANTOR          0.4887      0.206      2.372      0.018       0.085       0.892\n",
      "REAL_ESTATE        0.3207      0.107      3.002      0.003       0.111       0.530\n",
      "PROP_UNKN_NONE    -0.2773      0.125     -2.210      0.027      -0.523      -0.031\n",
      "AGE                0.0004      0.000      0.842      0.400      -0.001       0.001\n",
      "OTHER_INSTALL     -0.2602      0.109     -2.376      0.017      -0.475      -0.046\n",
      "RENT              -0.2928      0.126     -2.332      0.020      -0.539      -0.047\n",
      "OWN_RES            0.3238      0.115      2.820      0.005       0.099       0.549\n",
      "NUM_CREDITS        0.1429      0.098      1.451      0.147      -0.050       0.336\n",
      "JOB               -0.1613      0.070     -2.317      0.020      -0.298      -0.025\n",
      "NUM_DEPENDENTS    -0.0981      0.122     -0.805      0.421      -0.337       0.141\n",
      "TELEPHONE          0.1650      0.093      1.770      0.077      -0.018       0.348\n",
      "FOREIGN            0.5188      0.268      1.933      0.053      -0.007       1.045\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "f = remove_name_formula(['CO_APPLICANT'])\n",
    "logitfit = smf.logit(formula = f, data = data).fit()\n",
    "print(logitfit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50d8f757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.556042\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               RESPONSE   No. Observations:                 2931\n",
      "Model:                          Logit   Df Residuals:                     2908\n",
      "Method:                           MLE   Df Model:                           22\n",
      "Date:                Wed, 10 Nov 2021   Pseudo R-squ.:                  0.1067\n",
      "Time:                        17:06:10   Log-Likelihood:                -1629.8\n",
      "converged:                       True   LL-Null:                       -1824.4\n",
      "Covariance Type:            nonrobust   LLR p-value:                 6.816e-69\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept         -0.5163      0.253     -2.037      0.042      -1.013      -0.020\n",
      "CHK_ACCT           0.2952      0.035      8.397      0.000       0.226       0.364\n",
      "DURATION          -0.0155      0.004     -4.222      0.000      -0.023      -0.008\n",
      "HISTORY            0.2274      0.042      5.433      0.000       0.145       0.309\n",
      "USED_CAR           0.4483      0.151      2.965      0.003       0.152       0.745\n",
      "RADIO_TV           0.3118      0.105      2.968      0.003       0.106       0.518\n",
      "RETRAINING         0.1172      0.146      0.802      0.422      -0.169       0.404\n",
      "AMOUNT          3.194e-08   3.13e-08      1.020      0.308   -2.94e-08    9.33e-08\n",
      "SAV_ACCT           0.0935      0.029      3.252      0.001       0.037       0.150\n",
      "EMPLOYMENT         0.1638      0.036      4.549      0.000       0.093       0.234\n",
      "INSTALL_RATE      -0.1024      0.043     -2.395      0.017      -0.186      -0.019\n",
      "MALE_SINGLE        0.2814      0.091      3.078      0.002       0.102       0.461\n",
      "GUARANTOR          0.4864      0.206      2.362      0.018       0.083       0.890\n",
      "REAL_ESTATE        0.3212      0.107      3.006      0.003       0.112       0.531\n",
      "PROP_UNKN_NONE    -0.2817      0.125     -2.247      0.025      -0.527      -0.036\n",
      "AGE                0.0004      0.000      0.860      0.390      -0.001       0.001\n",
      "OTHER_INSTALL     -0.2621      0.109     -2.395      0.017      -0.477      -0.048\n",
      "RENT              -0.2869      0.125     -2.289      0.022      -0.533      -0.041\n",
      "OWN_RES            0.3273      0.115      2.852      0.004       0.102       0.552\n",
      "NUM_CREDITS        0.1369      0.098      1.394      0.163      -0.056       0.329\n",
      "JOB               -0.1568      0.069     -2.260      0.024      -0.293      -0.021\n",
      "TELEPHONE          0.1660      0.093      1.781      0.075      -0.017       0.349\n",
      "FOREIGN            0.5188      0.269      1.931      0.053      -0.008       1.045\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "f = remove_name_formula(['NUM_DEPENDENTS'])\n",
    "logitfit = smf.logit(formula = f, data = data).fit()\n",
    "print(logitfit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b076b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.556152\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               RESPONSE   No. Observations:                 2931\n",
      "Model:                          Logit   Df Residuals:                     2909\n",
      "Method:                           MLE   Df Model:                           21\n",
      "Date:                Wed, 10 Nov 2021   Pseudo R-squ.:                  0.1065\n",
      "Time:                        17:06:10   Log-Likelihood:                -1630.1\n",
      "converged:                       True   LL-Null:                       -1824.4\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.125e-69\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept         -0.5209      0.253     -2.056      0.040      -1.017      -0.024\n",
      "CHK_ACCT           0.2956      0.035      8.410      0.000       0.227       0.364\n",
      "DURATION          -0.0152      0.004     -4.167      0.000      -0.022      -0.008\n",
      "HISTORY            0.2267      0.042      5.418      0.000       0.145       0.309\n",
      "USED_CAR           0.4486      0.151      2.966      0.003       0.152       0.745\n",
      "RADIO_TV           0.3062      0.105      2.921      0.003       0.101       0.512\n",
      "AMOUNT          3.188e-08   3.13e-08      1.018      0.308   -2.95e-08    9.32e-08\n",
      "SAV_ACCT           0.0933      0.029      3.247      0.001       0.037       0.150\n",
      "EMPLOYMENT         0.1634      0.036      4.537      0.000       0.093       0.234\n",
      "INSTALL_RATE      -0.1037      0.043     -2.426      0.015      -0.187      -0.020\n",
      "MALE_SINGLE        0.2854      0.091      3.126      0.002       0.106       0.464\n",
      "GUARANTOR          0.4824      0.206      2.343      0.019       0.079       0.886\n",
      "REAL_ESTATE        0.3235      0.107      3.029      0.002       0.114       0.533\n",
      "PROP_UNKN_NONE    -0.2850      0.125     -2.274      0.023      -0.531      -0.039\n",
      "AGE                0.0004      0.000      0.898      0.369      -0.000       0.001\n",
      "OTHER_INSTALL     -0.2567      0.109     -2.351      0.019      -0.471      -0.043\n",
      "RENT              -0.2873      0.125     -2.292      0.022      -0.533      -0.042\n",
      "OWN_RES            0.3308      0.115      2.885      0.004       0.106       0.556\n",
      "NUM_CREDITS        0.1417      0.098      1.444      0.149      -0.051       0.334\n",
      "JOB               -0.1543      0.069     -2.227      0.026      -0.290      -0.019\n",
      "TELEPHONE          0.1689      0.093      1.814      0.070      -0.014       0.351\n",
      "FOREIGN            0.5133      0.268      1.912      0.056      -0.013       1.039\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "f = remove_name_formula(['RETRAINING'])\n",
    "logitfit = smf.logit(formula = f, data = data).fit()\n",
    "print(logitfit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf362566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.556296\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               RESPONSE   No. Observations:                 2931\n",
      "Model:                          Logit   Df Residuals:                     2910\n",
      "Method:                           MLE   Df Model:                           20\n",
      "Date:                Wed, 10 Nov 2021   Pseudo R-squ.:                  0.1063\n",
      "Time:                        17:06:10   Log-Likelihood:                -1630.5\n",
      "converged:                       True   LL-Null:                       -1824.4\n",
      "Covariance Type:            nonrobust   LLR p-value:                 7.087e-70\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept         -0.5068      0.253     -2.006      0.045      -1.002      -0.012\n",
      "CHK_ACCT           0.2950      0.035      8.398      0.000       0.226       0.364\n",
      "DURATION          -0.0153      0.004     -4.183      0.000      -0.022      -0.008\n",
      "HISTORY            0.2264      0.042      5.410      0.000       0.144       0.308\n",
      "USED_CAR           0.4490      0.151      2.969      0.003       0.153       0.745\n",
      "RADIO_TV           0.3048      0.105      2.909      0.004       0.099       0.510\n",
      "AMOUNT          3.169e-08   3.13e-08      1.013      0.311   -2.96e-08     9.3e-08\n",
      "SAV_ACCT           0.0935      0.029      3.255      0.001       0.037       0.150\n",
      "EMPLOYMENT         0.1641      0.036      4.558      0.000       0.094       0.235\n",
      "INSTALL_RATE      -0.1021      0.043     -2.390      0.017      -0.186      -0.018\n",
      "MALE_SINGLE        0.2885      0.091      3.163      0.002       0.110       0.467\n",
      "GUARANTOR          0.4828      0.206      2.344      0.019       0.079       0.887\n",
      "REAL_ESTATE        0.3235      0.107      3.030      0.002       0.114       0.533\n",
      "PROP_UNKN_NONE    -0.2841      0.125     -2.268      0.023      -0.530      -0.039\n",
      "OTHER_INSTALL     -0.2554      0.109     -2.339      0.019      -0.469      -0.041\n",
      "RENT              -0.2883      0.125     -2.300      0.021      -0.534      -0.043\n",
      "OWN_RES            0.3282      0.115      2.864      0.004       0.104       0.553\n",
      "NUM_CREDITS        0.1418      0.098      1.446      0.148      -0.050       0.334\n",
      "JOB               -0.1541      0.069     -2.224      0.026      -0.290      -0.018\n",
      "TELEPHONE          0.1713      0.093      1.841      0.066      -0.011       0.354\n",
      "FOREIGN            0.5107      0.268      1.903      0.057      -0.015       1.037\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "f = remove_name_formula(['AGE'])\n",
    "logitfit = smf.logit(formula = f, data = data).fit()\n",
    "print(logitfit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed4eebd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.556477\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               RESPONSE   No. Observations:                 2931\n",
      "Model:                          Logit   Df Residuals:                     2911\n",
      "Method:                           MLE   Df Model:                           19\n",
      "Date:                Wed, 10 Nov 2021   Pseudo R-squ.:                  0.1060\n",
      "Time:                        17:06:10   Log-Likelihood:                -1631.0\n",
      "converged:                       True   LL-Null:                       -1824.4\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.567e-70\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept         -0.5042      0.253     -1.995      0.046      -0.999      -0.009\n",
      "CHK_ACCT           0.2951      0.035      8.402      0.000       0.226       0.364\n",
      "DURATION          -0.0152      0.004     -4.150      0.000      -0.022      -0.008\n",
      "HISTORY            0.2263      0.042      5.410      0.000       0.144       0.308\n",
      "USED_CAR           0.4485      0.151      2.968      0.003       0.152       0.745\n",
      "RADIO_TV           0.3059      0.105      2.919      0.004       0.100       0.511\n",
      "SAV_ACCT           0.0933      0.029      3.248      0.001       0.037       0.150\n",
      "EMPLOYMENT         0.1641      0.036      4.560      0.000       0.094       0.235\n",
      "INSTALL_RATE      -0.1015      0.043     -2.378      0.017      -0.185      -0.018\n",
      "MALE_SINGLE        0.2876      0.091      3.153      0.002       0.109       0.466\n",
      "GUARANTOR          0.4810      0.206      2.335      0.020       0.077       0.885\n",
      "REAL_ESTATE        0.3248      0.107      3.043      0.002       0.116       0.534\n",
      "PROP_UNKN_NONE    -0.2830      0.125     -2.260      0.024      -0.528      -0.038\n",
      "OTHER_INSTALL     -0.2536      0.109     -2.323      0.020      -0.467      -0.040\n",
      "RENT              -0.2863      0.125     -2.285      0.022      -0.532      -0.041\n",
      "OWN_RES            0.3293      0.115      2.874      0.004       0.105       0.554\n",
      "NUM_CREDITS        0.1405      0.098      1.433      0.152      -0.052       0.333\n",
      "JOB               -0.1539      0.069     -2.222      0.026      -0.290      -0.018\n",
      "TELEPHONE          0.1701      0.093      1.829      0.067      -0.012       0.352\n",
      "FOREIGN            0.5069      0.268      1.889      0.059      -0.019       1.033\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "f = remove_name_formula(['AMOUNT'])\n",
    "logitfit = smf.logit(formula = f, data = data).fit()\n",
    "print(logitfit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76f193e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.556834\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               RESPONSE   No. Observations:                 2931\n",
      "Model:                          Logit   Df Residuals:                     2912\n",
      "Method:                           MLE   Df Model:                           18\n",
      "Date:                Wed, 10 Nov 2021   Pseudo R-squ.:                  0.1054\n",
      "Time:                        17:06:10   Log-Likelihood:                -1632.1\n",
      "converged:                       True   LL-Null:                       -1824.4\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.485e-70\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept         -0.3785      0.237     -1.600      0.110      -0.842       0.085\n",
      "CHK_ACCT           0.2963      0.035      8.441      0.000       0.227       0.365\n",
      "DURATION          -0.0151      0.004     -4.133      0.000      -0.022      -0.008\n",
      "HISTORY            0.2372      0.041      5.768      0.000       0.157       0.318\n",
      "USED_CAR           0.4505      0.151      2.981      0.003       0.154       0.747\n",
      "RADIO_TV           0.3036      0.105      2.899      0.004       0.098       0.509\n",
      "SAV_ACCT           0.0927      0.029      3.230      0.001       0.036       0.149\n",
      "EMPLOYMENT         0.1663      0.036      4.625      0.000       0.096       0.237\n",
      "INSTALL_RATE      -0.0988      0.043     -2.320      0.020      -0.182      -0.015\n",
      "MALE_SINGLE        0.2933      0.091      3.220      0.001       0.115       0.472\n",
      "GUARANTOR          0.4809      0.206      2.334      0.020       0.077       0.885\n",
      "REAL_ESTATE        0.3234      0.107      3.031      0.002       0.114       0.533\n",
      "PROP_UNKN_NONE    -0.2826      0.125     -2.257      0.024      -0.528      -0.037\n",
      "OTHER_INSTALL     -0.2459      0.109     -2.256      0.024      -0.460      -0.032\n",
      "RENT              -0.2899      0.125     -2.314      0.021      -0.535      -0.044\n",
      "OWN_RES            0.3272      0.115      2.856      0.004       0.103       0.552\n",
      "JOB               -0.1547      0.069     -2.235      0.025      -0.290      -0.019\n",
      "TELEPHONE          0.1747      0.093      1.879      0.060      -0.007       0.357\n",
      "FOREIGN            0.5086      0.268      1.897      0.058      -0.017       1.034\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "f = remove_name_formula(['NUM_CREDITS'])\n",
    "logitfit = smf.logit(formula = f, data = data).fit()\n",
    "print(logitfit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01bbc4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.557439\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               RESPONSE   No. Observations:                 2931\n",
      "Model:                          Logit   Df Residuals:                     2913\n",
      "Method:                           MLE   Df Model:                           17\n",
      "Date:                Wed, 10 Nov 2021   Pseudo R-squ.:                  0.1044\n",
      "Time:                        17:06:10   Log-Likelihood:                -1633.9\n",
      "converged:                       True   LL-Null:                       -1824.4\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.687e-70\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept         -0.3761      0.236     -1.592      0.111      -0.839       0.087\n",
      "CHK_ACCT           0.2998      0.035      8.554      0.000       0.231       0.368\n",
      "DURATION          -0.0143      0.004     -3.955      0.000      -0.021      -0.007\n",
      "HISTORY            0.2398      0.041      5.835      0.000       0.159       0.320\n",
      "USED_CAR           0.4678      0.151      3.102      0.002       0.172       0.763\n",
      "RADIO_TV           0.2982      0.105      2.852      0.004       0.093       0.503\n",
      "SAV_ACCT           0.0946      0.029      3.300      0.001       0.038       0.151\n",
      "EMPLOYMENT         0.1663      0.036      4.631      0.000       0.096       0.237\n",
      "INSTALL_RATE      -0.1011      0.043     -2.374      0.018      -0.184      -0.018\n",
      "MALE_SINGLE        0.3001      0.091      3.299      0.001       0.122       0.478\n",
      "GUARANTOR          0.4568      0.205      2.223      0.026       0.054       0.859\n",
      "REAL_ESTATE        0.3099      0.106      2.913      0.004       0.101       0.518\n",
      "PROP_UNKN_NONE    -0.2630      0.125     -2.110      0.035      -0.507      -0.019\n",
      "OTHER_INSTALL     -0.2497      0.109     -2.293      0.022      -0.463      -0.036\n",
      "RENT              -0.3015      0.125     -2.413      0.016      -0.546      -0.057\n",
      "OWN_RES            0.3303      0.114      2.889      0.004       0.106       0.554\n",
      "JOB               -0.1324      0.068     -1.946      0.052      -0.266       0.001\n",
      "FOREIGN            0.4941      0.268      1.841      0.066      -0.032       1.020\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "f = remove_name_formula(['TELEPHONE'])\n",
    "logitfit = smf.logit(formula = f, data = data).fit()\n",
    "print(logitfit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e10c0079",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.558060\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               RESPONSE   No. Observations:                 2931\n",
      "Model:                          Logit   Df Residuals:                     2914\n",
      "Method:                           MLE   Df Model:                           16\n",
      "Date:                Wed, 10 Nov 2021   Pseudo R-squ.:                  0.1034\n",
      "Time:                        17:06:11   Log-Likelihood:                -1635.7\n",
      "converged:                       True   LL-Null:                       -1824.4\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.961e-70\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept         -0.3351      0.235     -1.425      0.154      -0.796       0.126\n",
      "CHK_ACCT           0.2985      0.035      8.526      0.000       0.230       0.367\n",
      "DURATION          -0.0146      0.004     -4.035      0.000      -0.022      -0.008\n",
      "HISTORY            0.2406      0.041      5.861      0.000       0.160       0.321\n",
      "USED_CAR           0.4622      0.151      3.065      0.002       0.167       0.758\n",
      "RADIO_TV           0.2971      0.105      2.841      0.004       0.092       0.502\n",
      "SAV_ACCT           0.0945      0.029      3.300      0.001       0.038       0.151\n",
      "EMPLOYMENT         0.1676      0.036      4.669      0.000       0.097       0.238\n",
      "INSTALL_RATE      -0.1079      0.042     -2.545      0.011      -0.191      -0.025\n",
      "MALE_SINGLE        0.3004      0.091      3.305      0.001       0.122       0.479\n",
      "GUARANTOR          0.4635      0.206      2.252      0.024       0.060       0.867\n",
      "REAL_ESTATE        0.3156      0.106      2.970      0.003       0.107       0.524\n",
      "PROP_UNKN_NONE    -0.2669      0.125     -2.143      0.032      -0.511      -0.023\n",
      "OTHER_INSTALL     -0.2484      0.109     -2.281      0.023      -0.462      -0.035\n",
      "RENT              -0.2919      0.125     -2.342      0.019      -0.536      -0.048\n",
      "OWN_RES            0.3370      0.114      2.952      0.003       0.113       0.561\n",
      "JOB               -0.1395      0.068     -2.054      0.040      -0.273      -0.006\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "f = remove_name_formula(['FOREIGN'])\n",
    "logitfit = smf.logit(formula = f, data = data).fit()\n",
    "print(logitfit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52a7f4cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x280da5ea760>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logitfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1df24486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RESPONSE ~ CHK_ACCT+DURATION+HISTORY+USED_CAR+RADIO_TV+SAV_ACCT+EMPLOYMENT+INSTALL_RATE+MALE_SINGLE+GUARANTOR+REAL_ESTATE+PROP_UNKN_NONE+OTHER_INSTALL+RENT+OWN_RES+JOB'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "513a778e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and test split and scaling\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "Y = data['RESPONSE']\n",
    "X = data[['CHK_ACCT','DURATION','HISTORY','USED_CAR','RADIO_TV','SAV_ACCT','EMPLOYMENT','INSTALL_RATE','MALE_SINGLE','GUARANTOR','REAL_ESTATE','PROP_UNKN_NONE','OTHER_INSTALL','RENT','OWN_RES','JOB']]\n",
    "robust_scaler=RobustScaler()\n",
    "X=robust_scaler.fit_transform(X)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=0, test_size=.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "49b23b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features that we are going to use\n",
    "features =['CHK_ACCT','DURATION','HISTORY','USED_CAR','RADIO_TV','SAV_ACCT','EMPLOYMENT','INSTALL_RATE','MALE_SINGLE','GUARANTOR','REAL_ESTATE','PROP_UNKN_NONE','OTHER_INSTALL','RENT','OWN_RES','JOB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c472587a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training target statistics: Counter({1: 1599, 0: 1599})\n",
      "Testing target statistics: Counter({1: 411, 0: 176})\n"
     ]
    }
   ],
   "source": [
    "#simply balancing our X_train(now becomes X_res) and y_train(y_res)\n",
    "import collections\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "over_sampler = RandomOverSampler(random_state=42)\n",
    "x_res, y_res = over_sampler.fit_resample(x_train, y_train)\n",
    "print(f\"Training target statistics: {Counter(y_res)}\")\n",
    "print(f\"Testing target statistics: {Counter(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6fcbebeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2287c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noorus Suhaina\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.31422723 ...        nan 0.70965541 0.70965541]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter tuning\n",
    "param_grid = [    \n",
    "    {'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C' : np.logspace(-4, 4, 20),\n",
    "    'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "    'max_iter' : [100, 1000,2500, 5000]\n",
    "    }\n",
    "]\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "clf=GridSearchCV(classifier,param_grid = param_grid, cv = 3, verbose=True, n_jobs=-1)\n",
    "best_clf = clf.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4ad15527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.23357214690901212, random_state=0, solver='liblinear')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ed1389ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=LogisticRegression(C=0.23357214690901212, random_state=0, solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7fad0508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.23357214690901212, random_state=0, solver='liblinear')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bae8f65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probabilities = classifier.predict_proba(x_test)\n",
    "y_pred=classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a374944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[ 46 130]\n",
      " [ 42 369]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print (\"Confusion Matrix : \\n\", cm) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "13054821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.706984667802385\n",
      "Recall: 0.8978102189781022\n",
      "F1: 0.810989010989011\n",
      "precision: 0.7394789579158316\n"
     ]
    }
   ],
   "source": [
    "#evaluation metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "print (\"Accuracy : \", accuracy_score(y_test, y_pred))\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test,y_pred))\n",
    "print(\"F1:\",metrics.f1_score(y_test,y_pred))\n",
    "print(\"precision:\",metrics.precision_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3eee0d",
   "metadata": {},
   "source": [
    "Quick description of the evaluation metrics:\n",
    "High recall means a low false negative rate(where there is lesser number of people whom we classify as not defaulting when they actually default. (This is important for our problem set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "87dd132c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ROC-AUC\n",
      "0  0.579587\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n",
    " \n",
    "# Print the evaluation metrics as pandas dataframe\n",
    "score = pd.DataFrame({\"ROC-AUC\" : [metrics.auc(fpr, tpr)]})\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa45787",
   "metadata": {},
   "source": [
    "## Second Method of doing feature selection using recursive feature elimination using logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "486e1e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2931, 31)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e9e67aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn import metrics\n",
    "X = data.drop('RESPONSE',axis=1)\n",
    "Y = data['RESPONSE']\n",
    "robust_scaler=RobustScaler()\n",
    "X = pd.DataFrame(robust_scaler.fit_transform(X), columns = X.columns)\n",
    "#robust_scaler=RobustScaler()\n",
    "#X=robust_scaler.fit_transform(X)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=0, test_size=.20)\n",
    "#balance our dataset\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "x_res, y_res = sm.fit_resample(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "62f38cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(random_state = 0)\n",
    "rfe = RFECV(estimator=classifier, step=10, cv=KFold(n_splits=5, shuffle=False), scoring='roc_auc', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9e2b376c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 30 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noorus Suhaina\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Noorus Suhaina\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 30 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noorus Suhaina\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Noorus Suhaina\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 30 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noorus Suhaina\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Noorus Suhaina\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFECV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "      estimator=LogisticRegression(random_state=0), scoring='roc_auc', step=10,\n",
       "      verbose=2)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "645a894c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features: 20\n"
     ]
    }
   ],
   "source": [
    "print('Optimal number of features:', rfe.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ed71c0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selected features are:\n",
      "['CHK_ACCT', 'DURATION', 'HISTORY', 'USED_CAR', 'RADIO_TV', 'RETRAINING', 'SAV_ACCT', 'EMPLOYMENT', 'INSTALL_RATE', 'MALE_SINGLE', 'GUARANTOR', 'REAL_ESTATE', 'PROP_UNKN_NONE', 'OTHER_INSTALL', 'RENT', 'OWN_RES', 'NUM_CREDITS', 'JOB', 'TELEPHONE', 'FOREIGN']\n"
     ]
    }
   ],
   "source": [
    "features_rfecv = [f for f,s in zip(X, rfe.support_) if s]\n",
    "print('The selected features are:')\n",
    "print ('{}'.format(features_rfecv)) ## optimal features list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "54034211",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_rfe=['CHK_ACCT', 'DURATION', 'HISTORY', 'USED_CAR', 'RADIO_TV', 'RETRAINING', 'SAV_ACCT', 'EMPLOYMENT', 'INSTALL_RATE', 'MALE_SINGLE', 'GUARANTOR', 'REAL_ESTATE', 'PROP_UNKN_NONE', 'OTHER_INSTALL', 'RENT', 'OWN_RES', 'NUM_CREDITS', 'JOB', 'TELEPHONE', 'FOREIGN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7ec3ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lr = data[['CHK_ACCT', 'DURATION', 'HISTORY', 'USED_CAR', 'RADIO_TV', 'RETRAINING', 'SAV_ACCT', 'EMPLOYMENT', 'INSTALL_RATE', 'MALE_SINGLE', 'GUARANTOR', 'REAL_ESTATE', 'PROP_UNKN_NONE', 'OTHER_INSTALL', 'RENT', 'OWN_RES', 'NUM_CREDITS', 'JOB', 'TELEPHONE', 'FOREIGN']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_lr, Y, random_state=0, test_size=.20)\n",
    "robust_scaler=RobustScaler()\n",
    "X_lr = pd.DataFrame(robust_scaler.fit_transform(X_lr), columns = X_lr.columns)\n",
    "#balance our dataset\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "x_res, y_res = sm.fit_resample(x_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "64c143d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(x_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "acf0f703",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probabilities = classifier.predict_proba(x_test)\n",
    "y_pred=classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f59d9188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ROC-AUC\n",
      "0  0.617404\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n",
    " \n",
    "# Print the evaluation metrics as pandas dataframe\n",
    "score = pd.DataFrame({\"ROC-AUC\" : [metrics.auc(fpr, tpr)]})\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4c6fc421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting onto our test data set(given we choose this logistic regression model)\n",
    "test_predictions_prob = classifier.predict_proba(test_data[features_rfe])[:, 1]\n",
    "test_predictions=classifier.predict(test_data[features_rfe])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "535b7403",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'ID':test_data['ID'],'RESPONSE':test_predictions_prob})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d3cbb7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>RESPONSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3001</td>\n",
       "      <td>0.338583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3002</td>\n",
       "      <td>0.398435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3003</td>\n",
       "      <td>0.857291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3004</td>\n",
       "      <td>0.242517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3005</td>\n",
       "      <td>0.308173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  RESPONSE\n",
       "0  3001  0.338583\n",
       "1  3002  0.398435\n",
       "2  3003  0.857291\n",
       "3  3004  0.242517\n",
       "4  3005  0.308173"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8fd55881",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'RFE Logreg Predictions.csv'\n",
    "\n",
    "submission.to_csv(filename,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7c6660",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ccfa872e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('RESPONSE',axis=1)\n",
    "Y = data['RESPONSE']\n",
    "robust_scaler=RobustScaler()\n",
    "X = pd.DataFrame(robust_scaler.fit_transform(X), columns = X.columns)\n",
    "#robust_scaler=RobustScaler()\n",
    "#X=robust_scaler.fit_transform(X)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=0, test_size=.20)\n",
    "#balance our dataset\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "x_res, y_res = sm.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3f9283d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "442ec872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8ed078",
   "metadata": {},
   "source": [
    "The parameters that we need to tune for our random forest\n",
    "n_estimators = number of trees in the foreset\n",
    "max_features = max number of features considered for splitting a node\n",
    "max_depth = max number of levels in each decision tree\n",
    "min_samples_split = min number of data points placed in a node before the node is split\n",
    "min_samples_leaf = min number of data points allowed in a leaf node\n",
    "bootstrap = method for sampling data points (with or without replacement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a562cd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ce733729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "#use RandomForestRegressor() if this is not a classification problem\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(x_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "49da4d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1000,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 50,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting the best hyper parameters\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3ad01bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input the best hyperparameters over here\n",
    "rf_best=RandomForestClassifier(n_estimators= 1400,\n",
    " min_samples_split= 2,\n",
    " min_samples_leaf= 1,\n",
    " max_features= 'auto',\n",
    " max_depth= 40,\n",
    " bootstrap= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "13192047",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = RFECV(estimator=rf_best, step=10, cv=KFold(n_splits=5, shuffle=False), scoring='roc_auc', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "84ee1c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 10 features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFECV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "      estimator=RandomForestClassifier(bootstrap=False, max_depth=40,\n",
       "                                       n_estimators=1400),\n",
       "      scoring='roc_auc', step=10, verbose=2)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2d719a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features: 30\n"
     ]
    }
   ],
   "source": [
    "print('Optimal number of features:', rfe.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9d0f32f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selected features are:\n",
      "['CHK_ACCT', 'DURATION', 'HISTORY', 'NEW_CAR', 'USED_CAR', 'FURNITURE', 'RADIO_TV', 'EDUCATION', 'RETRAINING', 'AMOUNT', 'SAV_ACCT', 'EMPLOYMENT', 'INSTALL_RATE', 'MALE_DIV', 'MALE_SINGLE', 'MALE_MAR_or_WID', 'CO_APPLICANT', 'GUARANTOR', 'PRESENT_RESIDENT', 'REAL_ESTATE', 'PROP_UNKN_NONE', 'AGE', 'OTHER_INSTALL', 'RENT', 'OWN_RES', 'NUM_CREDITS', 'JOB', 'NUM_DEPENDENTS', 'TELEPHONE', 'FOREIGN']\n"
     ]
    }
   ],
   "source": [
    "features_rfecv = [f for f,s in zip(X, rfe.support_) if s]\n",
    "print('The selected features are:')\n",
    "print ('{}'.format(features_rfecv)) ## optimal features list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "daefd4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features selected from recurisve feature elimination\n",
    "X_rf = data[features_rfecv]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_rf, Y, random_state=0, test_size=.20)\n",
    "robust_scaler=RobustScaler()\n",
    "X_rf = pd.DataFrame(robust_scaler.fit_transform(X_rf))\n",
    "#balance our dataset\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "x_res, y_res = sm.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2209e3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best.fit(x_res,y_res)\n",
    "y_pred_probabilities = rf_best.predict_proba(x_test)\n",
    "y_pred=rf_best.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9c43e982",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ROC-AUC\n",
      "0  0.593826\n",
      "Accuracy: 0.681431\n",
      "Precision: 0.752252\n",
      "Recall: 0.812652\n",
      "F1 Score: 0.781287\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n",
    " \n",
    "# Print the evaluation metrics as pandas dataframe\n",
    "score = pd.DataFrame({\"ROC-AUC\" : [metrics.auc(fpr, tpr)]})\n",
    "print(score)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "print('Precision: %f' % precision)\n",
    "print('Recall: %f' % recall)\n",
    "print('F1 Score: %f' % f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1d8888",
   "metadata": {},
   "source": [
    "# XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "826927d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5e1e289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "X = data.drop('RESPONSE',axis=1)\n",
    "Y = data['RESPONSE']\n",
    "robust_scaler=RobustScaler()\n",
    "X = pd.DataFrame(robust_scaler.fit_transform(X), columns = X.columns)\n",
    "#robust_scaler=RobustScaler()\n",
    "#X=robust_scaler.fit_transform(X)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=0, test_size=.20)\n",
    "#balance our dataset\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "x_res, y_res = sm.fit_resample(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "092c0254",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noorus Suhaina\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:12:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 0.679727\n",
      "Precision: 0.755149\n",
      "Recall: 0.802920\n",
      "F1 Score: 0.778302\n",
      "AUC-ROC: 0.597483\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgbmodel = XGBClassifier()\n",
    "xgbmodel.fit(x_res, y_res)\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred_xgb = xgbmodel.predict(x_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, y_pred_xgb)\n",
    "precision = precision_score(y_test, y_pred_xgb)\n",
    "recall = recall_score(y_test, y_pred_xgb)\n",
    "f1 = f1_score(y_test, y_pred_xgb)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_xgb)\n",
    "\n",
    "y_pred_prob_xgb = xgbmodel.predict_proba(x_test)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "print('Precision: %f' % precision)\n",
    "print('Recall: %f' % recall)\n",
    "print('F1 Score: %f' % f1)\n",
    "print('AUC-ROC: %f' % roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7a263e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doing grid search cv to find optimal hyperparameters\n",
    "param_grid = {'subsample': [0.7],\n",
    " 'scale_pos_weight': [1],\n",
    " 'n_estimators': [1100],\n",
    " 'min_child_weight': [1],\n",
    " 'max_depth': [12, 13, 14],\n",
    " 'learning_rate': [0.005, 0.01],\n",
    " 'gamma': [4.0],\n",
    " 'colsample_bytree': [0.6]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c6790d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg = xgb.XGBClassifier(objective='binary:logistic', silent=True, nthread=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5d9c8b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator = xg, param_grid = param_grid, cv = 5, n_jobs = -1, verbose = 2, scoring = \"roc_auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8fe6efa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noorus Suhaina\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:13:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:13:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     enable_categorical=False, gamma=None,\n",
       "                                     gpu_id=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,...\n",
       "                                     reg_lambda=None, scale_pos_weight=None,\n",
       "                                     silent=True, subsample=None,\n",
       "                                     tree_method=None, validate_parameters=None,\n",
       "                                     verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.6], 'gamma': [4.0],\n",
       "                         'learning_rate': [0.005, 0.01],\n",
       "                         'max_depth': [12, 13, 14], 'min_child_weight': [1],\n",
       "                         'n_estimators': [1100], 'scale_pos_weight': [1],\n",
       "                         'subsample': [0.7]},\n",
       "             scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit grid search to data\n",
    "grid_search.fit(x_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "808b4c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.6,\n",
       " 'gamma': 4.0,\n",
       " 'learning_rate': 0.005,\n",
       " 'max_depth': 12,\n",
       " 'min_child_weight': 1,\n",
       " 'n_estimators': 1100,\n",
       " 'scale_pos_weight': 1,\n",
       " 'subsample': 0.7}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_grid = grid_search.best_params_\n",
    "best_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "254e7b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model with parameters found\n",
    "model_bestxgb = xgb.XGBClassifier(**best_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d68d159b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = RFECV(estimator=model_bestxgb, step=10, cv=KFold(n_splits=5, shuffle=False), scoring='roc_auc', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "11994424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 30 features.\n",
      "[17:13:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noorus Suhaina\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 20 features.\n",
      "[17:13:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noorus Suhaina\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 10 features.\n",
      "[17:13:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noorus Suhaina\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Noorus Suhaina\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting estimator with 30 features.\n",
      "[17:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noorus Suhaina\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 20 features.\n",
      "[17:13:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noorus Suhaina\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 10 features.\n",
      "[17:13:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noorus Suhaina\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Noorus Suhaina\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:13:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting estimator with 30 features.\n",
      "[17:13:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noorus Suhaina\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 20 features.\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noorus Suhaina\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 10 features.\n",
      "[17:14:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noorus Suhaina\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Noorus Suhaina\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:14:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting estimator with 30 features.\n",
      "[17:14:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noorus Suhaina\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 20 features.\n",
      "[17:14:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noorus Suhaina\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 10 features.\n",
      "[17:14:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noorus Suhaina\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Noorus Suhaina\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:14:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting estimator with 30 features.\n",
      "[17:14:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noorus Suhaina\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 20 features.\n",
      "[17:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noorus Suhaina\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 10 features.\n",
      "[17:14:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noorus Suhaina\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Noorus Suhaina\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:14:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noorus Suhaina\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:14:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noorus Suhaina\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:14:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFECV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "      estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                              colsample_bylevel=None, colsample_bynode=None,\n",
       "                              colsample_bytree=0.6, enable_categorical=False,\n",
       "                              gamma=4.0, gpu_id=None, importance_type=None,\n",
       "                              interaction_constraints=None, learning_rate=0.005,\n",
       "                              max_delta_step=None, max_depth=12,\n",
       "                              min_child_weight=1, missing=nan,\n",
       "                              monotone_constraints=None, n_estimators=1100,\n",
       "                              n_jobs=None, num_parallel_tree=None,\n",
       "                              predictor=None, random_state=None, reg_alpha=None,\n",
       "                              reg_lambda=None, scale_pos_weight=1,\n",
       "                              subsample=0.7, tree_method=None,\n",
       "                              validate_parameters=None, verbosity=None),\n",
       "      scoring='roc_auc', step=10, verbose=2)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a10f6315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features: 30\n"
     ]
    }
   ],
   "source": [
    "print('Optimal number of features:', rfe.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b9b76d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selected features are:\n",
      "['CHK_ACCT', 'DURATION', 'HISTORY', 'NEW_CAR', 'USED_CAR', 'FURNITURE', 'RADIO_TV', 'EDUCATION', 'RETRAINING', 'AMOUNT', 'SAV_ACCT', 'EMPLOYMENT', 'INSTALL_RATE', 'MALE_DIV', 'MALE_SINGLE', 'MALE_MAR_or_WID', 'CO_APPLICANT', 'GUARANTOR', 'PRESENT_RESIDENT', 'REAL_ESTATE', 'PROP_UNKN_NONE', 'AGE', 'OTHER_INSTALL', 'RENT', 'OWN_RES', 'NUM_CREDITS', 'JOB', 'NUM_DEPENDENTS', 'TELEPHONE', 'FOREIGN']\n"
     ]
    }
   ],
   "source": [
    "features_rfecv = [f for f,s in zip(X, rfe.support_) if s]\n",
    "print('The selected features are:')\n",
    "print ('{}'.format(features_rfecv)) ## optimal features list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "91804fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CHK_ACCT',\n",
       " 'DURATION',\n",
       " 'HISTORY',\n",
       " 'NEW_CAR',\n",
       " 'USED_CAR',\n",
       " 'FURNITURE',\n",
       " 'RADIO_TV',\n",
       " 'EDUCATION',\n",
       " 'RETRAINING',\n",
       " 'AMOUNT',\n",
       " 'SAV_ACCT',\n",
       " 'EMPLOYMENT',\n",
       " 'INSTALL_RATE',\n",
       " 'MALE_DIV',\n",
       " 'MALE_SINGLE',\n",
       " 'MALE_MAR_or_WID',\n",
       " 'CO_APPLICANT',\n",
       " 'GUARANTOR',\n",
       " 'PRESENT_RESIDENT',\n",
       " 'REAL_ESTATE',\n",
       " 'PROP_UNKN_NONE',\n",
       " 'AGE',\n",
       " 'OTHER_INSTALL',\n",
       " 'RENT',\n",
       " 'OWN_RES',\n",
       " 'NUM_CREDITS',\n",
       " 'JOB',\n",
       " 'NUM_DEPENDENTS',\n",
       " 'TELEPHONE',\n",
       " 'FOREIGN']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_rfecv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8f7b2681",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features selected from recurisve feature elimination\n",
    "X_xgb = data[['CHK_ACCT', 'DURATION', 'HISTORY', 'NEW_CAR', 'USED_CAR', 'FURNITURE', 'RADIO_TV', 'EDUCATION', 'RETRAINING', 'AMOUNT', 'SAV_ACCT', 'EMPLOYMENT', 'INSTALL_RATE', 'MALE_DIV', 'MALE_SINGLE', 'MALE_MAR_or_WID', 'CO_APPLICANT', 'GUARANTOR', 'PRESENT_RESIDENT', 'REAL_ESTATE', 'PROP_UNKN_NONE', 'AGE', 'OTHER_INSTALL', 'RENT', 'OWN_RES', 'NUM_CREDITS', 'JOB', 'NUM_DEPENDENTS', 'TELEPHONE', 'FOREIGN']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_xgb, Y, random_state=0, test_size=.20)\n",
    "robust_scaler=RobustScaler()\n",
    "X_xgb = pd.DataFrame(robust_scaler.fit_transform(X_xgb), columns = X_xgb.columns)\n",
    "#balance our dataset\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "x_res, y_res = sm.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fffdc390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:14:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noorus Suhaina\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "model_bestxgb.fit(x_res, y_res)\n",
    "y_pred_xgb = model_bestxgb.predict(x_test)\n",
    "y_pred_prob_xgb = model_bestxgb.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "eceb7111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.693356\n",
      "Precision: 0.766744\n",
      "Recall: 0.807786\n",
      "F1 Score: 0.786730\n",
      "AUC-ROC: 0.616961\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, y_pred_xgb)\n",
    "precision = precision_score(y_test, y_pred_xgb)\n",
    "recall = recall_score(y_test, y_pred_xgb)\n",
    "f1 = f1_score(y_test, y_pred_xgb)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_xgb)\n",
    "roc_auc\n",
    "print('Accuracy: %f' % accuracy)\n",
    "print('Precision: %f' % precision)\n",
    "print('Recall: %f' % recall)\n",
    "print('F1 Score: %f' % f1)\n",
    "print('AUC-ROC: %f' % roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ba6b07f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit xgboost predictions\n",
    "# fitting onto our test data set\n",
    "test_predictions_prob = model_bestxgb.predict_proba(test_data[features_rfecv])[:, 1]\n",
    "test_predictions=model_bestxgb.predict(test_data[features_rfecv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "03adac2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'ID':test_data['ID'],'RESPONSE':test_predictions_prob})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "088868bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>RESPONSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3001</td>\n",
       "      <td>0.436612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3002</td>\n",
       "      <td>0.756638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3003</td>\n",
       "      <td>0.867138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3004</td>\n",
       "      <td>0.151238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3005</td>\n",
       "      <td>0.068572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  RESPONSE\n",
       "0  3001  0.436612\n",
       "1  3002  0.756638\n",
       "2  3003  0.867138\n",
       "3  3004  0.151238\n",
       "4  3005  0.068572"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a8d745be",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'xgboostpredictions_rfecv.csv'\n",
    "\n",
    "submission.to_csv(filename,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "86dfaab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for luminus  submission need to output binary variables\n",
    "final_submission = pd.DataFrame({'ID':test_data['ID'],'RESPONSE':test_predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "be740cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>RESPONSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  RESPONSE\n",
       "0  3001         0\n",
       "1  3002         1\n",
       "2  3003         1\n",
       "3  3004         0\n",
       "4  3005         0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a7b514dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'xgboostpredictions_submission.csv'\n",
    "\n",
    "final_submission.to_csv(filename,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
